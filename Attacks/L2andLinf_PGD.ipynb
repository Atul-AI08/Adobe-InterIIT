{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install foolbox advertorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFJYe_JClgT5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import foolbox as fb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f7nXFakltra"
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cck1pjzpL-rR"
   },
   "source": [
    "## Test dataset attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqKnAD39oQB_"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"/content/test\"\n",
    "\n",
    "# Transformations for the dataset\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "\n",
    "# Load your dataset using ImageFolder (assuming dataset is structured by classes)\n",
    "\n",
    "kaggle_dataset = torchvision.datasets.ImageFolder(dataset_path, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    kaggle_dataset, batch_size=32, shuffle=False, num_workers=4, prefetch_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5LcdNVUqnuH"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True).to(device).eval()\n",
    "model.half()  # Convert model weights to FP16\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEn_HmqLqsLv"
   },
   "outputs": [],
   "source": [
    "attack = fb.attacks.L2ProjectedGradientDescentAttack(steps=10)\n",
    "\n",
    "# Define the path to save adversarial images\n",
    "adversarial_dataset_path = \"adversarial_dataset\"\n",
    "os.makedirs(adversarial_dataset_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWDIyXtArKMP",
    "outputId": "49991115-4feb-4ee4-88d4-653abd406f0e"
   },
   "outputs": [],
   "source": [
    "epsilons = 1.0\n",
    "\n",
    "for i, (inputs, labels) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Adversarial Generation\"):\n",
    "    # Move inputs and labels to device\n",
    "    inputs = inputs.to(device).half()  # Convert inputs to FP16\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Generate adversarial examples using Foolbox\n",
    "    with torch.cuda.amp.autocast():  # Enable mixed precision\n",
    "        raw_advs, clipped_advs, success = attack(fmodel, inputs, labels, epsilons=epsilons)\n",
    "\n",
    "    # Save adversarial images batch-wise\n",
    "    for idx in range(inputs.size(0)):\n",
    "        class_name = kaggle_dataset.classes[labels[idx].item()]\n",
    "        class_dir = os.path.join(adversarial_dataset_path, class_name)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        # Save individual adversarial image\n",
    "        image_path = os.path.join(class_dir, f\"adversarial_{i * 16 + idx}.png\")\n",
    "        torchvision.utils.save_image(clipped_advs[idx].float(), image_path)  # Convert back to float for saving\n",
    "\n",
    "print(f\"Adversarial images saved to {adversarial_dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kf2svPHarRaZ",
    "outputId": "f9720858-fda8-4c44-e2db-53979e1f8ef5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to already saved adversarial images\n",
    "saved_adversarial_path = \"/content/adversarial_dataset\"  # Path to the original adversarial dataset\n",
    "resized_adversarial_path = \"./adversarial_dataset_32x32\"  # Path to save resized images\n",
    "os.makedirs(resized_adversarial_path, exist_ok=True)\n",
    "\n",
    "# Define the resize transform\n",
    "resize_to_32 = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Iterate through all saved adversarial images\n",
    "for root, dirs, files in os.walk(saved_adversarial_path):\n",
    "    for class_name in tqdm(dirs, desc=\"Processing classes\"):\n",
    "        class_input_path = os.path.join(root, class_name)\n",
    "        class_output_path = os.path.join(resized_adversarial_path, class_name)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        for image_name in tqdm(os.listdir(class_input_path), desc=f\"Resizing {class_name}\", leave=False):\n",
    "            image_input_path = os.path.join(class_input_path, image_name)\n",
    "            image_output_path = os.path.join(class_output_path, image_name)\n",
    "\n",
    "            # Open and resize the image\n",
    "            try:\n",
    "                with Image.open(image_input_path) as img:\n",
    "                    img = resize_to_32(img)\n",
    "                    torchvision.utils.save_image(img, image_output_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {image_input_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkAkAx_P0X92",
    "outputId": "1a23423d-f6df-4c4e-b7dd-1722de675f98"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to the dataset folder\n",
    "dataset_path = \"/content/adversarial_dataset_inf_test\"  # Change to your folder path\n",
    "\n",
    "# Initialize counters\n",
    "total_images = 0\n",
    "class_image_count = {}\n",
    "\n",
    "# Traverse the directory\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for class_name in tqdm(dirs, desc=\"Counting images by class\"):\n",
    "        class_path = os.path.join(root, class_name)\n",
    "        image_count = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])\n",
    "        class_image_count[class_name] = image_count\n",
    "        total_images += image_count\n",
    "\n",
    "# Print results\n",
    "print(\"\\n--- Image Count by Class ---\")\n",
    "for class_name, count in class_image_count.items():\n",
    "    print(f\"{class_name}: {count} images\")\n",
    "\n",
    "print(f\"\\nTotal images: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "8MXH5Qdx0nR8",
    "outputId": "abd601ce-b628-4f9f-bb4e-5c1507c07817"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_b6665f27-072c-4b06-993d-fce243f1e03a\", \"adversarial_dataset_32x32.zip\", 22011071)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Path to the folder in Colab\n",
    "folder_to_download = \"./adversarial_dataset_32x32\"  # Replace with your folder path\n",
    "output_zip = \"./adversarial_dataset_32x32.zip\"\n",
    "\n",
    "# Compress the folder\n",
    "shutil.make_archive(output_zip.replace(\".zip\", \"\"), 'zip', folder_to_download)\n",
    "\n",
    "# Download the zipped folder\n",
    "files.download(output_zip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ2y7qaNL1-x"
   },
   "source": [
    "## Attack on Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "afvLBDmZ1Ab4",
    "outputId": "8b944027-7998-4318-8234-05abbe04eaf3"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset path\n",
    "dataset_path = \"/content/train\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UykKgu4KysUs",
    "outputId": "04345796-79f0-4b80-bd60-a32211c65477"
   },
   "outputs": [],
   "source": [
    "kaggle_dataset = torchvision.datasets.ImageFolder(dataset_path, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(kaggle_dataset, batch_size=8, shuffle=False, num_workers=4, prefetch_factor=2)\n",
    "\n",
    "# Load pre-trained ResNet50\n",
    "model = torchvision.models.resnet50(pretrained=True).to(device).eval()\n",
    "model.half()  # Mixed precision\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OegfRpNfyzn3"
   },
   "outputs": [],
   "source": [
    "attack = fb.attacks.L2ProjectedGradientDescentAttack(steps=10)\n",
    "epsilons = 1.0\n",
    "\n",
    "# Transform adversarial images back to 32x32\n",
    "resize_to_32 = transforms.Resize((32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dImg9maXzISu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import foolbox as fb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "JotSusbLy4h5",
    "outputId": "da9ed225-e11a-48e3-d3cd-3386b4b7724f"
   },
   "outputs": [],
   "source": [
    "adversarial_dataset_path = \"./adversarial_dataset_32x32\"\n",
    "os.makedirs(adversarial_dataset_path, exist_ok=True)\n",
    "\n",
    "# Process dataset\n",
    "for i, (inputs, labels) in tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), desc=\"Adversarial Generation\"\n",
    "):\n",
    "    try:\n",
    "        # Move inputs to device\n",
    "        inputs = inputs.to(device).half()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        with torch.cuda.amp.autocast():\n",
    "            raw_advs, clipped_advs, success = attack(\n",
    "                fmodel, inputs, labels, epsilons=epsilons\n",
    "            )\n",
    "\n",
    "        # Save images resized to 32x32 with the same filenames as originals, prefixed with \"adversarial_\"\n",
    "        for idx in range(inputs.size(0)):\n",
    "            # Get the original filename\n",
    "            original_path, _ = kaggle_dataset.samples[i * inputs.size(0) + idx]\n",
    "            original_filename = os.path.basename(original_path)\n",
    "            adversarial_filename = f\"adversarial_{original_filename}\"\n",
    "\n",
    "            # Create class directory in the output folder\n",
    "            class_name = kaggle_dataset.classes[labels[idx].item()]\n",
    "            class_dir = os.path.join(adversarial_dataset_path, class_name)\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "            # Resize adversarial image to 32x32 and save\n",
    "            adversarial_32x32 = resize_to_32(clipped_advs[idx].float().cpu())\n",
    "            image_path = os.path.join(class_dir, adversarial_filename)\n",
    "            torchvision.utils.save_image(adversarial_32x32, image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during batch {i + 1}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChDThNYWhppN"
   },
   "source": [
    "## Linf attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vnXb2fWhs3W"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset path\n",
    "dataset_path = \"/content/test\"\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFGE-Richtum",
    "outputId": "fdf9690c-7b44-42a1-a742-d15625288a38"
   },
   "outputs": [],
   "source": [
    "kaggle_dataset = torchvision.datasets.ImageFolder(dataset_path, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    kaggle_dataset, batch_size=8, shuffle=False, num_workers=4, prefetch_factor=2\n",
    ")\n",
    "\n",
    "# Load pre-trained ResNet50\n",
    "model = torchvision.models.resnet50(pretrained=True).to(device).eval()\n",
    "model.half()  # Mixed precision\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EILKx_J5hxtt"
   },
   "outputs": [],
   "source": [
    "attack = fb.attacks.LinfProjectedGradientDescentAttack(steps=10, rel_stepsize=0.1)\n",
    "epsilons = 16 / 255\n",
    "resize_to_32 = transforms.Resize((32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "170kofVch6wi",
    "outputId": "8952aea6-be19-4b5a-de42-33790751a690"
   },
   "outputs": [],
   "source": [
    "adversarial_dataset_path = \"./adversarial_dataset_inf_test\"\n",
    "os.makedirs(adversarial_dataset_path, exist_ok=True)\n",
    "\n",
    "# Process dataset\n",
    "for i, (inputs, labels) in tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), desc=\"Adversarial Generation\"\n",
    "):\n",
    "    try:\n",
    "        inputs = inputs.to(device).half()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        with torch.cuda.amp.autocast():\n",
    "            raw_advs, clipped_advs, success = attack(\n",
    "                fmodel, inputs, labels, epsilons=epsilons\n",
    "            )\n",
    "\n",
    "        for idx in range(inputs.size(0)):\n",
    "            # Get the original filename\n",
    "            original_path, _ = kaggle_dataset.samples[i * inputs.size(0) + idx]\n",
    "            original_filename = os.path.basename(original_path)\n",
    "            adversarial_filename = f\"adversarial_{original_filename}\"\n",
    "\n",
    "            # Create class directory in the output folder\n",
    "            class_name = kaggle_dataset.classes[labels[idx].item()]\n",
    "            class_dir = os.path.join(adversarial_dataset_path, class_name)\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "            adversarial_32x32 = resize_to_32(clipped_advs[idx].float().cpu())\n",
    "            image_path = os.path.join(class_dir, adversarial_filename)\n",
    "            torchvision.utils.save_image(adversarial_32x32, image_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during batch {i + 1}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
