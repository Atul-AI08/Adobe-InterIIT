{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFJYe_JClgT5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "5f7nXFakltra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6jsRXNxmele",
        "outputId": "6c967694-f687-4d0d-bebe-9ee293165e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d birdy654/cifake-real-and-ai-generated-synthetic-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeRbA5eGmzpB",
        "outputId": "c2c8224d-10fd-4ad0-cb1d-1a17e769f9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\n",
            "License(s): other\n",
            "Downloading cifake-real-and-ai-generated-synthetic-images.zip to /content\n",
            " 99% 104M/105M [00:05<00:00, 23.6MB/s]\n",
            "100% 105M/105M [00:05<00:00, 19.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install foolbox\n",
        "!pip install advertorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u351b8Svm6aK",
        "outputId": "3f6a1716-ec20-4c8d-f832-a84432f72ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from foolbox) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from foolbox) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from foolbox) (75.1.0)\n",
            "Collecting eagerpy>=0.30.0 (from foolbox)\n",
            "  Downloading eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from foolbox) (3.1.43)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from foolbox) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from foolbox) (2.32.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->foolbox) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->foolbox) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->foolbox) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->foolbox) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.1)\n",
            "Downloading foolbox-3.3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: eagerpy, foolbox\n",
            "Successfully installed eagerpy-0.30.0 foolbox-3.3.4\n",
            "Collecting advertorch\n",
            "  Downloading advertorch-0.2.3.tar.gz (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: advertorch\n",
            "  Building wheel for advertorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for advertorch: filename=advertorch-0.2.3-py3-none-any.whl size=5696198 sha256=e7dfa26ceddcdf3d142d67cdfbd377d7fb07c1abbec7ff2d22d3ebb0aa2facf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/00/de/d11c024ea240dfcf62cd3a94e1653bbb26139777243701dbf5\n",
            "Successfully built advertorch\n",
            "Installing collected packages: advertorch\n",
            "Successfully installed advertorch-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import foolbox as fb"
      ],
      "metadata": {
        "id": "Hxt6hiejnEa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test dataset attack\n"
      ],
      "metadata": {
        "id": "cck1pjzpL-rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/test\"  # Update with your local path\n",
        "\n",
        "# Define transformations for the dataset (resize to 224x224 for ResNet50)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images for ResNet50 input\n",
        "    transforms.ToTensor()           # Convert images to tensors\n",
        "])\n",
        "\n",
        "# Load your dataset using ImageFolder (assuming dataset is structured by classes)\n",
        "\n",
        "\n",
        "kaggle_dataset = torchvision.datasets.ImageFolder(dataset_path, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(kaggle_dataset, batch_size=32, shuffle=False, num_workers=4, prefetch_factor=2)"
      ],
      "metadata": {
        "id": "EqKnAD39oQB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet50(pretrained=True).to(device).eval()\n",
        "model.half()  # Convert model weights to FP16\n",
        "fmodel = fb.PyTorchModel(model, bounds=(0, 1))"
      ],
      "metadata": {
        "id": "G5LcdNVUqnuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack = fb.attacks.L2ProjectedGradientDescentAttack(steps=10)\n",
        "\n",
        "# Define the path to save adversarial images\n",
        "adversarial_dataset_path = \"adversarial_dataset\"  # Update this path\n",
        "os.makedirs(adversarial_dataset_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "LEn_HmqLqsLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilons = 1.0"
      ],
      "metadata": {
        "id": "uoI5F1Auq0v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "nkQvKjvZrEE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (inputs, labels) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Adversarial Generation\"):\n",
        "    # Move inputs and labels to device\n",
        "    inputs = inputs.to(device).half()  # Convert inputs to FP16\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Generate adversarial examples using Foolbox\n",
        "    with torch.cuda.amp.autocast():  # Enable mixed precision\n",
        "        raw_advs, clipped_advs, success = attack(fmodel, inputs, labels, epsilons=epsilons)\n",
        "\n",
        "    # Save adversarial images batch-wise\n",
        "    for idx in range(inputs.size(0)):\n",
        "        class_name = kaggle_dataset.classes[labels[idx].item()]\n",
        "        class_dir = os.path.join(adversarial_dataset_path, class_name)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        # Save individual adversarial image\n",
        "        image_path = os.path.join(class_dir, f\"adversarial_{i * 16 + idx}.png\")\n",
        "        torchvision.utils.save_image(clipped_advs[idx].float(), image_path)  # Convert back to float for saving\n",
        "\n",
        "print(f\"Adversarial images saved to {adversarial_dataset_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWDIyXtArKMP",
        "outputId": "49991115-4feb-4ee4-88d4-653abd406f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Adversarial Generation:   0%|          | 0/625 [00:00<?, ?it/s]<ipython-input-32-e63102d5eb39>:7: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # Enable mixed precision\n",
            "Adversarial Generation: 100%|██████████| 625/625 [23:41<00:00,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial images saved to adversarial_dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Path to already saved adversarial images\n",
        "saved_adversarial_path = \"/content/adversarial_dataset\"  # Path to the original adversarial dataset\n",
        "resized_adversarial_path = \"./adversarial_dataset_32x32\"  # Path to save resized images\n",
        "os.makedirs(resized_adversarial_path, exist_ok=True)\n",
        "\n",
        "# Define the resize transform\n",
        "resize_to_32 = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Iterate through all saved adversarial images\n",
        "for root, dirs, files in os.walk(saved_adversarial_path):\n",
        "    for class_name in tqdm(dirs, desc=\"Processing classes\"):\n",
        "        class_input_path = os.path.join(root, class_name)\n",
        "        class_output_path = os.path.join(resized_adversarial_path, class_name)\n",
        "        os.makedirs(class_output_path, exist_ok=True)\n",
        "\n",
        "        for image_name in tqdm(os.listdir(class_input_path), desc=f\"Resizing {class_name}\", leave=False):\n",
        "            image_input_path = os.path.join(class_input_path, image_name)\n",
        "            image_output_path = os.path.join(class_output_path, image_name)\n",
        "\n",
        "            # Open and resize the image\n",
        "            try:\n",
        "                with Image.open(image_input_path) as img:\n",
        "                    img = resize_to_32(img)\n",
        "                    torchvision.utils.save_image(img, image_output_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process {image_input_path}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf2svPHarRaZ",
        "outputId": "f9720858-fda8-4c44-e2db-53979e1f8ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing classes:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Resizing REAL:   0%|          | 0/5008 [00:00<?, ?it/s]\u001b[A\n",
            "Resizing REAL:   1%|          | 30/5008 [00:00<00:16, 293.04it/s]\u001b[A\n",
            "Resizing REAL:   1%|          | 60/5008 [00:00<00:17, 289.02it/s]\u001b[A\n",
            "Resizing REAL:   2%|▏         | 92/5008 [00:00<00:16, 297.09it/s]\u001b[A\n",
            "Resizing REAL:   2%|▏         | 122/5008 [00:00<00:16, 287.69it/s]\u001b[A\n",
            "Resizing REAL:   3%|▎         | 153/5008 [00:00<00:16, 292.98it/s]\u001b[A\n",
            "Resizing REAL:   4%|▎         | 186/5008 [00:00<00:15, 302.48it/s]\u001b[A\n",
            "Resizing REAL:   4%|▍         | 218/5008 [00:00<00:15, 307.55it/s]\u001b[A\n",
            "Resizing REAL:   5%|▍         | 250/5008 [00:00<00:15, 311.32it/s]\u001b[A\n",
            "Resizing REAL:   6%|▌         | 282/5008 [00:00<00:15, 300.28it/s]\u001b[A\n",
            "Resizing REAL:   6%|▋         | 313/5008 [00:01<00:15, 299.07it/s]\u001b[A\n",
            "Resizing REAL:   7%|▋         | 343/5008 [00:01<00:15, 297.77it/s]\u001b[A\n",
            "Resizing REAL:   8%|▊         | 376/5008 [00:01<00:15, 305.08it/s]\u001b[A\n",
            "Resizing REAL:   8%|▊         | 409/5008 [00:01<00:14, 309.79it/s]\u001b[A\n",
            "Resizing REAL:   9%|▉         | 442/5008 [00:01<00:14, 313.07it/s]\u001b[A\n",
            "Resizing REAL:   9%|▉         | 474/5008 [00:01<00:14, 312.98it/s]\u001b[A\n",
            "Resizing REAL:  10%|█         | 506/5008 [00:01<00:14, 314.94it/s]\u001b[A\n",
            "Resizing REAL:  11%|█         | 538/5008 [00:01<00:14, 316.23it/s]\u001b[A\n",
            "Resizing REAL:  11%|█▏        | 570/5008 [00:01<00:14, 313.00it/s]\u001b[A\n",
            "Resizing REAL:  12%|█▏        | 602/5008 [00:01<00:14, 301.33it/s]\u001b[A\n",
            "Resizing REAL:  13%|█▎        | 635/5008 [00:02<00:14, 307.13it/s]\u001b[A\n",
            "Resizing REAL:  13%|█▎        | 666/5008 [00:02<00:14, 303.75it/s]\u001b[A\n",
            "Resizing REAL:  14%|█▍        | 699/5008 [00:02<00:13, 309.93it/s]\u001b[A\n",
            "Resizing REAL:  15%|█▍        | 731/5008 [00:02<00:13, 312.48it/s]\u001b[A\n",
            "Resizing REAL:  15%|█▌        | 763/5008 [00:02<00:13, 311.18it/s]\u001b[A\n",
            "Resizing REAL:  16%|█▌        | 795/5008 [00:02<00:13, 311.86it/s]\u001b[A\n",
            "Resizing REAL:  17%|█▋        | 827/5008 [00:02<00:13, 313.89it/s]\u001b[A\n",
            "Resizing REAL:  17%|█▋        | 860/5008 [00:02<00:13, 316.41it/s]\u001b[A\n",
            "Resizing REAL:  18%|█▊        | 892/5008 [00:02<00:13, 308.04it/s]\u001b[A\n",
            "Resizing REAL:  18%|█▊        | 923/5008 [00:03<00:13, 302.59it/s]\u001b[A\n",
            "Resizing REAL:  19%|█▉        | 955/5008 [00:03<00:13, 305.67it/s]\u001b[A\n",
            "Resizing REAL:  20%|█▉        | 986/5008 [00:03<00:13, 302.18it/s]\u001b[A\n",
            "Resizing REAL:  20%|██        | 1018/5008 [00:03<00:13, 305.79it/s]\u001b[A\n",
            "Resizing REAL:  21%|██        | 1051/5008 [00:03<00:12, 310.50it/s]\u001b[A\n",
            "Resizing REAL:  22%|██▏       | 1083/5008 [00:03<00:12, 311.13it/s]\u001b[A\n",
            "Resizing REAL:  22%|██▏       | 1116/5008 [00:03<00:12, 314.22it/s]\u001b[A\n",
            "Resizing REAL:  23%|██▎       | 1148/5008 [00:03<00:12, 315.85it/s]\u001b[A\n",
            "Resizing REAL:  24%|██▎       | 1180/5008 [00:03<00:12, 314.24it/s]\u001b[A\n",
            "Resizing REAL:  24%|██▍       | 1212/5008 [00:03<00:12, 302.40it/s]\u001b[A\n",
            "Resizing REAL:  25%|██▍       | 1243/5008 [00:04<00:12, 304.37it/s]\u001b[A\n",
            "Resizing REAL:  25%|██▌       | 1275/5008 [00:04<00:12, 308.17it/s]\u001b[A\n",
            "Resizing REAL:  26%|██▌       | 1306/5008 [00:04<00:12, 304.78it/s]\u001b[A\n",
            "Resizing REAL:  27%|██▋       | 1338/5008 [00:04<00:11, 307.15it/s]\u001b[A\n",
            "Resizing REAL:  27%|██▋       | 1370/5008 [00:04<00:11, 309.88it/s]\u001b[A\n",
            "Resizing REAL:  28%|██▊       | 1402/5008 [00:04<00:11, 310.92it/s]\u001b[A\n",
            "Resizing REAL:  29%|██▊       | 1434/5008 [00:04<00:11, 313.27it/s]\u001b[A\n",
            "Resizing REAL:  29%|██▉       | 1466/5008 [00:04<00:11, 315.16it/s]\u001b[A\n",
            "Resizing REAL:  30%|██▉       | 1498/5008 [00:04<00:11, 313.70it/s]\u001b[A\n",
            "Resizing REAL:  31%|███       | 1530/5008 [00:04<00:11, 299.04it/s]\u001b[A\n",
            "Resizing REAL:  31%|███       | 1562/5008 [00:05<00:11, 303.63it/s]\u001b[A\n",
            "Resizing REAL:  32%|███▏      | 1595/5008 [00:05<00:11, 308.96it/s]\u001b[A\n",
            "Resizing REAL:  32%|███▏      | 1626/5008 [00:05<00:11, 305.25it/s]\u001b[A\n",
            "Resizing REAL:  33%|███▎      | 1657/5008 [00:05<00:11, 301.16it/s]\u001b[A\n",
            "Resizing REAL:  34%|███▎      | 1689/5008 [00:05<00:10, 305.51it/s]\u001b[A\n",
            "Resizing REAL:  34%|███▍      | 1720/5008 [00:05<00:10, 304.86it/s]\u001b[A\n",
            "Resizing REAL:  35%|███▍      | 1752/5008 [00:05<00:10, 308.05it/s]\u001b[A\n",
            "Resizing REAL:  36%|███▌      | 1785/5008 [00:05<00:10, 312.42it/s]\u001b[A\n",
            "Resizing REAL:  36%|███▋      | 1817/5008 [00:05<00:10, 305.68it/s]\u001b[A\n",
            "Resizing REAL:  37%|███▋      | 1848/5008 [00:06<00:10, 301.94it/s]\u001b[A\n",
            "Resizing REAL:  38%|███▊      | 1881/5008 [00:06<00:10, 307.88it/s]\u001b[A\n",
            "Resizing REAL:  38%|███▊      | 1912/5008 [00:06<00:10, 308.42it/s]\u001b[A\n",
            "Resizing REAL:  39%|███▉      | 1943/5008 [00:06<00:10, 298.20it/s]\u001b[A\n",
            "Resizing REAL:  39%|███▉      | 1973/5008 [00:06<00:10, 280.41it/s]\u001b[A\n",
            "Resizing REAL:  40%|███▉      | 2002/5008 [00:06<00:11, 261.56it/s]\u001b[A\n",
            "Resizing REAL:  41%|████      | 2029/5008 [00:06<00:11, 250.09it/s]\u001b[A\n",
            "Resizing REAL:  41%|████      | 2055/5008 [00:06<00:12, 240.91it/s]\u001b[A\n",
            "Resizing REAL:  42%|████▏     | 2080/5008 [00:06<00:13, 217.61it/s]\u001b[A\n",
            "Resizing REAL:  42%|████▏     | 2103/5008 [00:07<00:13, 211.95it/s]\u001b[A\n",
            "Resizing REAL:  42%|████▏     | 2126/5008 [00:07<00:13, 215.33it/s]\u001b[A\n",
            "Resizing REAL:  43%|████▎     | 2148/5008 [00:07<00:13, 213.25it/s]\u001b[A\n",
            "Resizing REAL:  43%|████▎     | 2170/5008 [00:07<00:13, 211.59it/s]\u001b[A\n",
            "Resizing REAL:  44%|████▍     | 2192/5008 [00:07<00:13, 210.71it/s]\u001b[A\n",
            "Resizing REAL:  44%|████▍     | 2214/5008 [00:07<00:13, 209.49it/s]\u001b[A\n",
            "Resizing REAL:  45%|████▍     | 2235/5008 [00:07<00:13, 209.55it/s]\u001b[A\n",
            "Resizing REAL:  45%|████▌     | 2257/5008 [00:07<00:13, 210.65it/s]\u001b[A\n",
            "Resizing REAL:  46%|████▌     | 2279/5008 [00:07<00:13, 207.23it/s]\u001b[A\n",
            "Resizing REAL:  46%|████▌     | 2300/5008 [00:08<00:13, 204.97it/s]\u001b[A\n",
            "Resizing REAL:  46%|████▋     | 2322/5008 [00:08<00:12, 209.26it/s]\u001b[A\n",
            "Resizing REAL:  47%|████▋     | 2343/5008 [00:08<00:12, 205.24it/s]\u001b[A\n",
            "Resizing REAL:  47%|████▋     | 2364/5008 [00:08<00:12, 204.78it/s]\u001b[A\n",
            "Resizing REAL:  48%|████▊     | 2386/5008 [00:08<00:12, 208.23it/s]\u001b[A\n",
            "Resizing REAL:  48%|████▊     | 2407/5008 [00:08<00:12, 208.21it/s]\u001b[A\n",
            "Resizing REAL:  49%|████▊     | 2430/5008 [00:08<00:12, 213.02it/s]\u001b[A\n",
            "Resizing REAL:  49%|████▉     | 2453/5008 [00:08<00:11, 217.94it/s]\u001b[A\n",
            "Resizing REAL:  49%|████▉     | 2476/5008 [00:08<00:11, 218.79it/s]\u001b[A\n",
            "Resizing REAL:  50%|████▉     | 2502/5008 [00:08<00:10, 230.25it/s]\u001b[A\n",
            "Resizing REAL:  51%|█████     | 2533/5008 [00:09<00:09, 253.19it/s]\u001b[A\n",
            "Resizing REAL:  51%|█████     | 2565/5008 [00:09<00:08, 272.33it/s]\u001b[A\n",
            "Resizing REAL:  52%|█████▏    | 2598/5008 [00:09<00:08, 287.67it/s]\u001b[A\n",
            "Resizing REAL:  53%|█████▎    | 2630/5008 [00:09<00:08, 297.11it/s]\u001b[A\n",
            "Resizing REAL:  53%|█████▎    | 2660/5008 [00:09<00:07, 295.91it/s]\u001b[A\n",
            "Resizing REAL:  54%|█████▎    | 2691/5008 [00:09<00:07, 298.56it/s]\u001b[A\n",
            "Resizing REAL:  54%|█████▍    | 2722/5008 [00:09<00:07, 301.85it/s]\u001b[A\n",
            "Resizing REAL:  55%|█████▌    | 2755/5008 [00:09<00:07, 307.56it/s]\u001b[A\n",
            "Resizing REAL:  56%|█████▌    | 2786/5008 [00:09<00:07, 306.98it/s]\u001b[A\n",
            "Resizing REAL:  56%|█████▋    | 2817/5008 [00:09<00:07, 297.54it/s]\u001b[A\n",
            "Resizing REAL:  57%|█████▋    | 2848/5008 [00:10<00:07, 299.64it/s]\u001b[A\n",
            "Resizing REAL:  58%|█████▊    | 2880/5008 [00:10<00:07, 303.51it/s]\u001b[A\n",
            "Resizing REAL:  58%|█████▊    | 2911/5008 [00:10<00:06, 305.09it/s]\u001b[A\n",
            "Resizing REAL:  59%|█████▊    | 2942/5008 [00:10<00:06, 303.86it/s]\u001b[A\n",
            "Resizing REAL:  59%|█████▉    | 2973/5008 [00:10<00:06, 299.81it/s]\u001b[A\n",
            "Resizing REAL:  60%|█████▉    | 3004/5008 [00:10<00:06, 297.43it/s]\u001b[A\n",
            "Resizing REAL:  61%|██████    | 3036/5008 [00:10<00:06, 303.50it/s]\u001b[A\n",
            "Resizing REAL:  61%|██████▏   | 3068/5008 [00:10<00:06, 308.22it/s]\u001b[A\n",
            "Resizing REAL:  62%|██████▏   | 3099/5008 [00:10<00:06, 303.78it/s]\u001b[A\n",
            "Resizing REAL:  62%|██████▎   | 3130/5008 [00:11<00:06, 298.67it/s]\u001b[A\n",
            "Resizing REAL:  63%|██████▎   | 3162/5008 [00:11<00:06, 304.05it/s]\u001b[A\n",
            "Resizing REAL:  64%|██████▍   | 3194/5008 [00:11<00:05, 306.22it/s]\u001b[A\n",
            "Resizing REAL:  64%|██████▍   | 3226/5008 [00:11<00:05, 309.09it/s]\u001b[A\n",
            "Resizing REAL:  65%|██████▌   | 3258/5008 [00:11<00:05, 311.74it/s]\u001b[A\n",
            "Resizing REAL:  66%|██████▌   | 3290/5008 [00:11<00:05, 306.47it/s]\u001b[A\n",
            "Resizing REAL:  66%|██████▋   | 3322/5008 [00:11<00:05, 308.54it/s]\u001b[A\n",
            "Resizing REAL:  67%|██████▋   | 3354/5008 [00:11<00:05, 310.78it/s]\u001b[A\n",
            "Resizing REAL:  68%|██████▊   | 3387/5008 [00:11<00:05, 314.41it/s]\u001b[A\n",
            "Resizing REAL:  68%|██████▊   | 3419/5008 [00:11<00:05, 302.58it/s]\u001b[A\n",
            "Resizing REAL:  69%|██████▉   | 3450/5008 [00:12<00:05, 301.27it/s]\u001b[A\n",
            "Resizing REAL:  70%|██████▉   | 3482/5008 [00:12<00:04, 306.23it/s]\u001b[A\n",
            "Resizing REAL:  70%|███████   | 3514/5008 [00:12<00:04, 306.79it/s]\u001b[A\n",
            "Resizing REAL:  71%|███████   | 3546/5008 [00:12<00:04, 309.88it/s]\u001b[A\n",
            "Resizing REAL:  71%|███████▏  | 3578/5008 [00:12<00:04, 308.67it/s]\u001b[A\n",
            "Resizing REAL:  72%|███████▏  | 3609/5008 [00:12<00:04, 306.03it/s]\u001b[A\n",
            "Resizing REAL:  73%|███████▎  | 3641/5008 [00:12<00:04, 308.75it/s]\u001b[A\n",
            "Resizing REAL:  73%|███████▎  | 3673/5008 [00:12<00:04, 311.57it/s]\u001b[A\n",
            "Resizing REAL:  74%|███████▍  | 3705/5008 [00:12<00:04, 311.44it/s]\u001b[A\n",
            "Resizing REAL:  75%|███████▍  | 3737/5008 [00:12<00:04, 301.33it/s]\u001b[A\n",
            "Resizing REAL:  75%|███████▌  | 3770/5008 [00:13<00:04, 307.17it/s]\u001b[A\n",
            "Resizing REAL:  76%|███████▌  | 3802/5008 [00:13<00:03, 309.59it/s]\u001b[A\n",
            "Resizing REAL:  77%|███████▋  | 3834/5008 [00:13<00:03, 312.29it/s]\u001b[A\n",
            "Resizing REAL:  77%|███████▋  | 3866/5008 [00:13<00:03, 312.69it/s]\u001b[A\n",
            "Resizing REAL:  78%|███████▊  | 3898/5008 [00:13<00:03, 311.46it/s]\u001b[A\n",
            "Resizing REAL:  78%|███████▊  | 3930/5008 [00:13<00:03, 307.84it/s]\u001b[A\n",
            "Resizing REAL:  79%|███████▉  | 3961/5008 [00:13<00:03, 308.15it/s]\u001b[A\n",
            "Resizing REAL:  80%|███████▉  | 3992/5008 [00:13<00:03, 306.94it/s]\u001b[A\n",
            "Resizing REAL:  80%|████████  | 4023/5008 [00:13<00:03, 301.62it/s]\u001b[A\n",
            "Resizing REAL:  81%|████████  | 4054/5008 [00:14<00:03, 299.73it/s]\u001b[A\n",
            "Resizing REAL:  82%|████████▏ | 4085/5008 [00:14<00:03, 302.64it/s]\u001b[A\n",
            "Resizing REAL:  82%|████████▏ | 4117/5008 [00:14<00:02, 307.39it/s]\u001b[A\n",
            "Resizing REAL:  83%|████████▎ | 4149/5008 [00:14<00:02, 310.50it/s]\u001b[A\n",
            "Resizing REAL:  83%|████████▎ | 4181/5008 [00:14<00:02, 310.80it/s]\u001b[A\n",
            "Resizing REAL:  84%|████████▍ | 4213/5008 [00:14<00:02, 308.22it/s]\u001b[A\n",
            "Resizing REAL:  85%|████████▍ | 4244/5008 [00:14<00:02, 305.66it/s]\u001b[A\n",
            "Resizing REAL:  85%|████████▌ | 4276/5008 [00:14<00:02, 309.20it/s]\u001b[A\n",
            "Resizing REAL:  86%|████████▌ | 4309/5008 [00:14<00:02, 312.84it/s]\u001b[A\n",
            "Resizing REAL:  87%|████████▋ | 4341/5008 [00:14<00:02, 299.94it/s]\u001b[A\n",
            "Resizing REAL:  87%|████████▋ | 4372/5008 [00:15<00:02, 300.01it/s]\u001b[A\n",
            "Resizing REAL:  88%|████████▊ | 4404/5008 [00:15<00:01, 303.76it/s]\u001b[A\n",
            "Resizing REAL:  89%|████████▊ | 4436/5008 [00:15<00:01, 308.44it/s]\u001b[A\n",
            "Resizing REAL:  89%|████████▉ | 4468/5008 [00:15<00:01, 310.71it/s]\u001b[A\n",
            "Resizing REAL:  90%|████████▉ | 4500/5008 [00:15<00:01, 309.37it/s]\u001b[A\n",
            "Resizing REAL:  90%|█████████ | 4531/5008 [00:15<00:01, 307.25it/s]\u001b[A\n",
            "Resizing REAL:  91%|█████████ | 4562/5008 [00:15<00:01, 291.99it/s]\u001b[A\n",
            "Resizing REAL:  92%|█████████▏| 4594/5008 [00:15<00:01, 298.74it/s]\u001b[A\n",
            "Resizing REAL:  92%|█████████▏| 4625/5008 [00:15<00:01, 297.69it/s]\u001b[A\n",
            "Resizing REAL:  93%|█████████▎| 4655/5008 [00:15<00:01, 295.05it/s]\u001b[A\n",
            "Resizing REAL:  94%|█████████▎| 4687/5008 [00:16<00:01, 301.62it/s]\u001b[A\n",
            "Resizing REAL:  94%|█████████▍| 4719/5008 [00:16<00:00, 305.56it/s]\u001b[A\n",
            "Resizing REAL:  95%|█████████▍| 4751/5008 [00:16<00:00, 307.99it/s]\u001b[A\n",
            "Resizing REAL:  96%|█████████▌| 4783/5008 [00:16<00:00, 310.10it/s]\u001b[A\n",
            "Resizing REAL:  96%|█████████▌| 4816/5008 [00:16<00:00, 314.06it/s]\u001b[A\n",
            "Resizing REAL:  97%|█████████▋| 4848/5008 [00:16<00:00, 306.70it/s]\u001b[A\n",
            "Resizing REAL:  97%|█████████▋| 4880/5008 [00:16<00:00, 308.91it/s]\u001b[A\n",
            "Resizing REAL:  98%|█████████▊| 4912/5008 [00:16<00:00, 310.63it/s]\u001b[A\n",
            "Resizing REAL:  99%|█████████▊| 4944/5008 [00:16<00:00, 301.57it/s]\u001b[A\n",
            "Resizing REAL:  99%|█████████▉| 4975/5008 [00:17<00:00, 297.86it/s]\u001b[A\n",
            "Resizing REAL: 100%|█████████▉| 5007/5008 [00:17<00:00, 303.22it/s]\u001b[A\n",
            "Processing classes:  50%|█████     | 1/2 [00:17<00:17, 17.16s/it]\n",
            "Resizing FAKE:   0%|          | 0/5008 [00:00<?, ?it/s]\u001b[A\n",
            "Resizing FAKE:   1%|          | 34/5008 [00:00<00:14, 334.23it/s]\u001b[A\n",
            "Resizing FAKE:   1%|▏         | 68/5008 [00:00<00:15, 321.33it/s]\u001b[A\n",
            "Resizing FAKE:   2%|▏         | 101/5008 [00:00<00:15, 309.54it/s]\u001b[A\n",
            "Resizing FAKE:   3%|▎         | 133/5008 [00:00<00:15, 309.05it/s]\u001b[A\n",
            "Resizing FAKE:   3%|▎         | 164/5008 [00:00<00:16, 300.28it/s]\u001b[A\n",
            "Resizing FAKE:   4%|▍         | 197/5008 [00:00<00:15, 307.01it/s]\u001b[A\n",
            "Resizing FAKE:   5%|▍         | 228/5008 [00:00<00:15, 302.90it/s]\u001b[A\n",
            "Resizing FAKE:   5%|▌         | 259/5008 [00:00<00:16, 295.27it/s]\u001b[A\n",
            "Resizing FAKE:   6%|▌         | 291/5008 [00:00<00:15, 302.27it/s]\u001b[A\n",
            "Resizing FAKE:   6%|▋         | 324/5008 [00:01<00:15, 308.00it/s]\u001b[A\n",
            "Resizing FAKE:   7%|▋         | 356/5008 [00:01<00:14, 310.15it/s]\u001b[A\n",
            "Resizing FAKE:   8%|▊         | 388/5008 [00:01<00:14, 312.78it/s]\u001b[A\n",
            "Resizing FAKE:   8%|▊         | 420/5008 [00:01<00:14, 313.83it/s]\u001b[A\n",
            "Resizing FAKE:   9%|▉         | 452/5008 [00:01<00:14, 313.81it/s]\u001b[A\n",
            "Resizing FAKE:  10%|▉         | 484/5008 [00:01<00:14, 302.17it/s]\u001b[A\n",
            "Resizing FAKE:  10%|█         | 516/5008 [00:01<00:14, 304.89it/s]\u001b[A\n",
            "Resizing FAKE:  11%|█         | 547/5008 [00:01<00:16, 277.49it/s]\u001b[A\n",
            "Resizing FAKE:  12%|█▏        | 576/5008 [00:01<00:17, 256.00it/s]\u001b[A\n",
            "Resizing FAKE:  12%|█▏        | 603/5008 [00:02<00:17, 248.70it/s]\u001b[A\n",
            "Resizing FAKE:  13%|█▎        | 629/5008 [00:02<00:18, 242.96it/s]\u001b[A\n",
            "Resizing FAKE:  13%|█▎        | 654/5008 [00:02<00:18, 237.98it/s]\u001b[A\n",
            "Resizing FAKE:  14%|█▎        | 678/5008 [00:02<00:18, 233.73it/s]\u001b[A\n",
            "Resizing FAKE:  14%|█▍        | 702/5008 [00:02<00:18, 226.73it/s]\u001b[A\n",
            "Resizing FAKE:  14%|█▍        | 725/5008 [00:02<00:19, 223.30it/s]\u001b[A\n",
            "Resizing FAKE:  15%|█▍        | 748/5008 [00:02<00:19, 221.11it/s]\u001b[A\n",
            "Resizing FAKE:  15%|█▌        | 771/5008 [00:02<00:19, 219.06it/s]\u001b[A\n",
            "Resizing FAKE:  16%|█▌        | 793/5008 [00:02<00:19, 217.47it/s]\u001b[A\n",
            "Resizing FAKE:  16%|█▋        | 815/5008 [00:03<00:19, 215.61it/s]\u001b[A\n",
            "Resizing FAKE:  17%|█▋        | 838/5008 [00:03<00:19, 218.15it/s]\u001b[A\n",
            "Resizing FAKE:  17%|█▋        | 861/5008 [00:03<00:18, 219.89it/s]\u001b[A\n",
            "Resizing FAKE:  18%|█▊        | 884/5008 [00:03<00:18, 220.32it/s]\u001b[A\n",
            "Resizing FAKE:  18%|█▊        | 907/5008 [00:03<00:18, 219.57it/s]\u001b[A\n",
            "Resizing FAKE:  19%|█▊        | 929/5008 [00:03<00:19, 214.40it/s]\u001b[A\n",
            "Resizing FAKE:  19%|█▉        | 952/5008 [00:03<00:18, 216.58it/s]\u001b[A\n",
            "Resizing FAKE:  19%|█▉        | 974/5008 [00:03<00:18, 216.86it/s]\u001b[A\n",
            "Resizing FAKE:  20%|█▉        | 996/5008 [00:03<00:18, 216.40it/s]\u001b[A\n",
            "Resizing FAKE:  20%|██        | 1019/5008 [00:03<00:18, 217.74it/s]\u001b[A\n",
            "Resizing FAKE:  21%|██        | 1042/5008 [00:04<00:18, 218.79it/s]\u001b[A\n",
            "Resizing FAKE:  21%|██        | 1064/5008 [00:04<00:18, 217.49it/s]\u001b[A\n",
            "Resizing FAKE:  22%|██▏       | 1087/5008 [00:04<00:17, 218.65it/s]\u001b[A\n",
            "Resizing FAKE:  22%|██▏       | 1113/5008 [00:04<00:16, 229.53it/s]\u001b[A\n",
            "Resizing FAKE:  23%|██▎       | 1145/5008 [00:04<00:15, 253.51it/s]\u001b[A\n",
            "Resizing FAKE:  23%|██▎       | 1176/5008 [00:04<00:14, 268.64it/s]\u001b[A\n",
            "Resizing FAKE:  24%|██▍       | 1204/5008 [00:04<00:14, 271.58it/s]\u001b[A\n",
            "Resizing FAKE:  25%|██▍       | 1232/5008 [00:04<00:13, 270.19it/s]\u001b[A\n",
            "Resizing FAKE:  25%|██▌       | 1263/5008 [00:04<00:13, 280.05it/s]\u001b[A\n",
            "Resizing FAKE:  26%|██▌       | 1295/5008 [00:05<00:12, 289.94it/s]\u001b[A\n",
            "Resizing FAKE:  26%|██▋       | 1327/5008 [00:05<00:12, 297.39it/s]\u001b[A\n",
            "Resizing FAKE:  27%|██▋       | 1359/5008 [00:05<00:12, 302.37it/s]\u001b[A\n",
            "Resizing FAKE:  28%|██▊       | 1391/5008 [00:05<00:11, 307.13it/s]\u001b[A\n",
            "Resizing FAKE:  28%|██▊       | 1423/5008 [00:05<00:11, 310.62it/s]\u001b[A\n",
            "Resizing FAKE:  29%|██▉       | 1455/5008 [00:05<00:11, 310.14it/s]\u001b[A\n",
            "Resizing FAKE:  30%|██▉       | 1488/5008 [00:05<00:11, 313.52it/s]\u001b[A\n",
            "Resizing FAKE:  30%|███       | 1520/5008 [00:05<00:11, 301.60it/s]\u001b[A\n",
            "Resizing FAKE:  31%|███       | 1551/5008 [00:05<00:11, 297.67it/s]\u001b[A\n",
            "Resizing FAKE:  32%|███▏      | 1583/5008 [00:05<00:11, 302.93it/s]\u001b[A\n",
            "Resizing FAKE:  32%|███▏      | 1615/5008 [00:06<00:11, 306.53it/s]\u001b[A\n",
            "Resizing FAKE:  33%|███▎      | 1647/5008 [00:06<00:10, 309.43it/s]\u001b[A\n",
            "Resizing FAKE:  34%|███▎      | 1679/5008 [00:06<00:10, 310.89it/s]\u001b[A\n",
            "Resizing FAKE:  34%|███▍      | 1711/5008 [00:06<00:10, 312.47it/s]\u001b[A\n",
            "Resizing FAKE:  35%|███▍      | 1743/5008 [00:06<00:10, 312.91it/s]\u001b[A\n",
            "Resizing FAKE:  35%|███▌      | 1775/5008 [00:06<00:10, 313.05it/s]\u001b[A\n",
            "Resizing FAKE:  36%|███▌      | 1807/5008 [00:06<00:10, 314.30it/s]\u001b[A\n",
            "Resizing FAKE:  37%|███▋      | 1839/5008 [00:06<00:10, 299.38it/s]\u001b[A\n",
            "Resizing FAKE:  37%|███▋      | 1870/5008 [00:06<00:10, 294.46it/s]\u001b[A\n",
            "Resizing FAKE:  38%|███▊      | 1902/5008 [00:06<00:10, 301.65it/s]\u001b[A\n",
            "Resizing FAKE:  39%|███▊      | 1934/5008 [00:07<00:10, 305.03it/s]\u001b[A\n",
            "Resizing FAKE:  39%|███▉      | 1966/5008 [00:07<00:09, 308.79it/s]\u001b[A\n",
            "Resizing FAKE:  40%|███▉      | 1998/5008 [00:07<00:09, 310.77it/s]\u001b[A\n",
            "Resizing FAKE:  41%|████      | 2030/5008 [00:07<00:09, 313.22it/s]\u001b[A\n",
            "Resizing FAKE:  41%|████      | 2062/5008 [00:07<00:09, 313.25it/s]\u001b[A\n",
            "Resizing FAKE:  42%|████▏     | 2094/5008 [00:07<00:09, 313.38it/s]\u001b[A\n",
            "Resizing FAKE:  42%|████▏     | 2126/5008 [00:07<00:09, 314.00it/s]\u001b[A\n",
            "Resizing FAKE:  43%|████▎     | 2158/5008 [00:07<00:09, 292.78it/s]\u001b[A\n",
            "Resizing FAKE:  44%|████▎     | 2190/5008 [00:07<00:09, 298.46it/s]\u001b[A\n",
            "Resizing FAKE:  44%|████▍     | 2222/5008 [00:08<00:09, 302.91it/s]\u001b[A\n",
            "Resizing FAKE:  45%|████▌     | 2254/5008 [00:08<00:09, 305.98it/s]\u001b[A\n",
            "Resizing FAKE:  46%|████▌     | 2286/5008 [00:08<00:08, 309.22it/s]\u001b[A\n",
            "Resizing FAKE:  46%|████▋     | 2318/5008 [00:08<00:08, 310.80it/s]\u001b[A\n",
            "Resizing FAKE:  47%|████▋     | 2350/5008 [00:08<00:08, 308.84it/s]\u001b[A\n",
            "Resizing FAKE:  48%|████▊     | 2381/5008 [00:08<00:08, 309.05it/s]\u001b[A\n",
            "Resizing FAKE:  48%|████▊     | 2413/5008 [00:08<00:08, 310.82it/s]\u001b[A\n",
            "Resizing FAKE:  49%|████▉     | 2445/5008 [00:08<00:09, 277.21it/s]\u001b[A\n",
            "Resizing FAKE:  49%|████▉     | 2474/5008 [00:08<00:09, 279.48it/s]\u001b[A\n",
            "Resizing FAKE:  50%|█████     | 2505/5008 [00:08<00:08, 286.91it/s]\u001b[A\n",
            "Resizing FAKE:  51%|█████     | 2537/5008 [00:09<00:08, 295.21it/s]\u001b[A\n",
            "Resizing FAKE:  51%|█████▏    | 2569/5008 [00:09<00:08, 302.07it/s]\u001b[A\n",
            "Resizing FAKE:  52%|█████▏    | 2601/5008 [00:09<00:07, 305.42it/s]\u001b[A\n",
            "Resizing FAKE:  53%|█████▎    | 2633/5008 [00:09<00:07, 308.39it/s]\u001b[A\n",
            "Resizing FAKE:  53%|█████▎    | 2665/5008 [00:09<00:07, 309.63it/s]\u001b[A\n",
            "Resizing FAKE:  54%|█████▍    | 2697/5008 [00:09<00:07, 312.35it/s]\u001b[A\n",
            "Resizing FAKE:  55%|█████▍    | 2730/5008 [00:09<00:07, 314.98it/s]\u001b[A\n",
            "Resizing FAKE:  55%|█████▌    | 2762/5008 [00:09<00:07, 291.21it/s]\u001b[A\n",
            "Resizing FAKE:  56%|█████▌    | 2793/5008 [00:09<00:07, 295.63it/s]\u001b[A\n",
            "Resizing FAKE:  56%|█████▋    | 2825/5008 [00:10<00:07, 301.63it/s]\u001b[A\n",
            "Resizing FAKE:  57%|█████▋    | 2857/5008 [00:10<00:07, 306.40it/s]\u001b[A\n",
            "Resizing FAKE:  58%|█████▊    | 2889/5008 [00:10<00:06, 309.91it/s]\u001b[A\n",
            "Resizing FAKE:  58%|█████▊    | 2921/5008 [00:10<00:06, 311.53it/s]\u001b[A\n",
            "Resizing FAKE:  59%|█████▉    | 2953/5008 [00:10<00:06, 313.70it/s]\u001b[A\n",
            "Resizing FAKE:  60%|█████▉    | 2985/5008 [00:10<00:06, 312.82it/s]\u001b[A\n",
            "Resizing FAKE:  60%|██████    | 3017/5008 [00:10<00:06, 314.44it/s]\u001b[A\n",
            "Resizing FAKE:  61%|██████    | 3049/5008 [00:10<00:06, 306.63it/s]\u001b[A\n",
            "Resizing FAKE:  62%|██████▏   | 3080/5008 [00:10<00:06, 296.18it/s]\u001b[A\n",
            "Resizing FAKE:  62%|██████▏   | 3111/5008 [00:10<00:06, 300.13it/s]\u001b[A\n",
            "Resizing FAKE:  63%|██████▎   | 3142/5008 [00:11<00:06, 302.50it/s]\u001b[A\n",
            "Resizing FAKE:  63%|██████▎   | 3174/5008 [00:11<00:05, 307.04it/s]\u001b[A\n",
            "Resizing FAKE:  64%|██████▍   | 3207/5008 [00:11<00:05, 310.85it/s]\u001b[A\n",
            "Resizing FAKE:  65%|██████▍   | 3239/5008 [00:11<00:05, 311.11it/s]\u001b[A\n",
            "Resizing FAKE:  65%|██████▌   | 3271/5008 [00:11<00:05, 313.06it/s]\u001b[A\n",
            "Resizing FAKE:  66%|██████▌   | 3303/5008 [00:11<00:05, 311.20it/s]\u001b[A\n",
            "Resizing FAKE:  67%|██████▋   | 3335/5008 [00:11<00:05, 312.45it/s]\u001b[A\n",
            "Resizing FAKE:  67%|██████▋   | 3367/5008 [00:11<00:05, 302.17it/s]\u001b[A\n",
            "Resizing FAKE:  68%|██████▊   | 3398/5008 [00:11<00:05, 294.33it/s]\u001b[A\n",
            "Resizing FAKE:  68%|██████▊   | 3430/5008 [00:11<00:05, 301.20it/s]\u001b[A\n",
            "Resizing FAKE:  69%|██████▉   | 3462/5008 [00:12<00:05, 304.88it/s]\u001b[A\n",
            "Resizing FAKE:  70%|██████▉   | 3494/5008 [00:12<00:04, 306.98it/s]\u001b[A\n",
            "Resizing FAKE:  70%|███████   | 3526/5008 [00:12<00:04, 308.96it/s]\u001b[A\n",
            "Resizing FAKE:  71%|███████   | 3558/5008 [00:12<00:04, 309.76it/s]\u001b[A\n",
            "Resizing FAKE:  72%|███████▏  | 3590/5008 [00:12<00:04, 310.67it/s]\u001b[A\n",
            "Resizing FAKE:  72%|███████▏  | 3622/5008 [00:12<00:04, 311.85it/s]\u001b[A\n",
            "Resizing FAKE:  73%|███████▎  | 3654/5008 [00:12<00:04, 310.25it/s]\u001b[A\n",
            "Resizing FAKE:  74%|███████▎  | 3686/5008 [00:12<00:04, 296.08it/s]\u001b[A\n",
            "Resizing FAKE:  74%|███████▍  | 3716/5008 [00:12<00:04, 284.83it/s]\u001b[A\n",
            "Resizing FAKE:  75%|███████▍  | 3747/5008 [00:13<00:04, 290.98it/s]\u001b[A\n",
            "Resizing FAKE:  75%|███████▌  | 3779/5008 [00:13<00:04, 299.03it/s]\u001b[A\n",
            "Resizing FAKE:  76%|███████▌  | 3811/5008 [00:13<00:03, 302.63it/s]\u001b[A\n",
            "Resizing FAKE:  77%|███████▋  | 3842/5008 [00:13<00:03, 294.20it/s]\u001b[A\n",
            "Resizing FAKE:  77%|███████▋  | 3873/5008 [00:13<00:03, 297.09it/s]\u001b[A\n",
            "Resizing FAKE:  78%|███████▊  | 3905/5008 [00:13<00:03, 301.45it/s]\u001b[A\n",
            "Resizing FAKE:  79%|███████▊  | 3937/5008 [00:13<00:03, 306.42it/s]\u001b[A\n",
            "Resizing FAKE:  79%|███████▉  | 3968/5008 [00:13<00:03, 298.63it/s]\u001b[A\n",
            "Resizing FAKE:  80%|███████▉  | 3998/5008 [00:13<00:03, 295.24it/s]\u001b[A\n",
            "Resizing FAKE:  80%|████████  | 4028/5008 [00:13<00:03, 289.97it/s]\u001b[A\n",
            "Resizing FAKE:  81%|████████  | 4058/5008 [00:14<00:03, 289.98it/s]\u001b[A\n",
            "Resizing FAKE:  82%|████████▏ | 4089/5008 [00:14<00:03, 295.67it/s]\u001b[A\n",
            "Resizing FAKE:  82%|████████▏ | 4121/5008 [00:14<00:02, 301.47it/s]\u001b[A\n",
            "Resizing FAKE:  83%|████████▎ | 4152/5008 [00:14<00:02, 291.20it/s]\u001b[A\n",
            "Resizing FAKE:  84%|████████▎ | 4182/5008 [00:14<00:03, 266.82it/s]\u001b[A\n",
            "Resizing FAKE:  84%|████████▍ | 4210/5008 [00:14<00:03, 253.61it/s]\u001b[A\n",
            "Resizing FAKE:  85%|████████▍ | 4236/5008 [00:14<00:03, 222.59it/s]\u001b[A\n",
            "Resizing FAKE:  85%|████████▌ | 4260/5008 [00:14<00:03, 213.47it/s]\u001b[A\n",
            "Resizing FAKE:  86%|████████▌ | 4282/5008 [00:15<00:03, 201.57it/s]\u001b[A\n",
            "Resizing FAKE:  86%|████████▌ | 4304/5008 [00:15<00:03, 204.23it/s]\u001b[A\n",
            "Resizing FAKE:  86%|████████▋ | 4325/5008 [00:15<00:03, 204.48it/s]\u001b[A\n",
            "Resizing FAKE:  87%|████████▋ | 4347/5008 [00:15<00:03, 206.47it/s]\u001b[A\n",
            "Resizing FAKE:  87%|████████▋ | 4370/5008 [00:15<00:03, 211.09it/s]\u001b[A\n",
            "Resizing FAKE:  88%|████████▊ | 4392/5008 [00:15<00:02, 212.37it/s]\u001b[A\n",
            "Resizing FAKE:  88%|████████▊ | 4414/5008 [00:15<00:02, 211.74it/s]\u001b[A\n",
            "Resizing FAKE:  89%|████████▊ | 4436/5008 [00:15<00:02, 203.73it/s]\u001b[A\n",
            "Resizing FAKE:  89%|████████▉ | 4458/5008 [00:15<00:02, 207.95it/s]\u001b[A\n",
            "Resizing FAKE:  89%|████████▉ | 4479/5008 [00:16<00:02, 206.02it/s]\u001b[A\n",
            "Resizing FAKE:  90%|████████▉ | 4500/5008 [00:16<00:02, 204.41it/s]\u001b[A\n",
            "Resizing FAKE:  90%|█████████ | 4522/5008 [00:16<00:02, 208.80it/s]\u001b[A\n",
            "Resizing FAKE:  91%|█████████ | 4544/5008 [00:16<00:02, 210.86it/s]\u001b[A\n",
            "Resizing FAKE:  91%|█████████ | 4566/5008 [00:16<00:02, 212.91it/s]\u001b[A\n",
            "Resizing FAKE:  92%|█████████▏| 4588/5008 [00:16<00:01, 212.93it/s]\u001b[A\n",
            "Resizing FAKE:  92%|█████████▏| 4610/5008 [00:16<00:01, 213.69it/s]\u001b[A\n",
            "Resizing FAKE:  92%|█████████▏| 4632/5008 [00:16<00:01, 213.98it/s]\u001b[A\n",
            "Resizing FAKE:  93%|█████████▎| 4654/5008 [00:16<00:01, 214.39it/s]\u001b[A\n",
            "Resizing FAKE:  93%|█████████▎| 4676/5008 [00:16<00:01, 214.14it/s]\u001b[A\n",
            "Resizing FAKE:  94%|█████████▍| 4703/5008 [00:17<00:01, 229.62it/s]\u001b[A\n",
            "Resizing FAKE:  94%|█████████▍| 4732/5008 [00:17<00:01, 246.05it/s]\u001b[A\n",
            "Resizing FAKE:  95%|█████████▌| 4764/5008 [00:17<00:00, 266.35it/s]\u001b[A\n",
            "Resizing FAKE:  96%|█████████▌| 4796/5008 [00:17<00:00, 281.29it/s]\u001b[A\n",
            "Resizing FAKE:  96%|█████████▋| 4827/5008 [00:17<00:00, 289.72it/s]\u001b[A\n",
            "Resizing FAKE:  97%|█████████▋| 4858/5008 [00:17<00:00, 294.50it/s]\u001b[A\n",
            "Resizing FAKE:  98%|█████████▊| 4890/5008 [00:17<00:00, 301.10it/s]\u001b[A\n",
            "Resizing FAKE:  98%|█████████▊| 4921/5008 [00:17<00:00, 296.61it/s]\u001b[A\n",
            "Resizing FAKE:  99%|█████████▉| 4951/5008 [00:17<00:00, 292.07it/s]\u001b[A\n",
            "Resizing FAKE:  99%|█████████▉| 4982/5008 [00:17<00:00, 295.82it/s]\u001b[A\n",
            "Processing classes: 100%|██████████| 2/2 [00:35<00:00, 17.61s/it]\n",
            "Processing classes: 0it [00:00, ?it/s]\n",
            "Processing classes: 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Path to the dataset folder\n",
        "dataset_path = \"/content/adversarial_dataset_inf_test\"  # Change to your folder path\n",
        "\n",
        "# Initialize counters\n",
        "total_images = 0\n",
        "class_image_count = {}\n",
        "\n",
        "# Traverse the directory\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for class_name in tqdm(dirs, desc=\"Counting images by class\"):\n",
        "        class_path = os.path.join(root, class_name)\n",
        "        image_count = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])\n",
        "        class_image_count[class_name] = image_count\n",
        "        total_images += image_count\n",
        "\n",
        "# Print results\n",
        "print(\"\\n--- Image Count by Class ---\")\n",
        "for class_name, count in class_image_count.items():\n",
        "    print(f\"{class_name}: {count} images\")\n",
        "\n",
        "print(f\"\\nTotal images: {total_images}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkAkAx_P0X92",
        "outputId": "1a23423d-f6df-4c4e-b7dd-1722de675f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting images by class: 100%|██████████| 2/2 [00:00<00:00, 13.99it/s]\n",
            "Counting images by class: 0it [00:00, ?it/s]\n",
            "Counting images by class: 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Image Count by Class ---\n",
            "FAKE: 10000 images\n",
            "REAL: 10000 images\n",
            "\n",
            "Total images: 20000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Path to the folder in Colab\n",
        "folder_to_download = \"./adversarial_dataset_32x32\"  # Replace with your folder path\n",
        "output_zip = \"./adversarial_dataset_32x32.zip\"\n",
        "\n",
        "# Compress the folder\n",
        "shutil.make_archive(output_zip.replace(\".zip\", \"\"), 'zip', folder_to_download)\n",
        "\n",
        "# Download the zipped folder\n",
        "files.download(output_zip)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8MXH5Qdx0nR8",
        "outputId": "abd601ce-b628-4f9f-bb4e-5c1507c07817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b6665f27-072c-4b06-993d-fce243f1e03a\", \"adversarial_dataset_32x32.zip\", 22011071)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack on Training data"
      ],
      "metadata": {
        "id": "aZ2y7qaNL1-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/train\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Ensure input matches the original size (32x32)\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "afvLBDmZ1Ab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "8b944027-7998-4318-8234-05abbe04eaf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1c80b59b0dba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Dataset path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m transform = transforms.Compose([\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_dataset = torchvision.datasets.ImageFolder(dataset_path, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(kaggle_dataset, batch_size=8, shuffle=False, num_workers=4, prefetch_factor=2)\n",
        "\n",
        "# Load pre-trained ResNet50\n",
        "model = torchvision.models.resnet50(pretrained=True).to(device).eval()\n",
        "model.half()  # Mixed precision\n",
        "fmodel = fb.PyTorchModel(model, bounds=(0, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UykKgu4KysUs",
        "outputId": "04345796-79f0-4b80-bd60-a32211c65477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 88.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack = fb.attacks.L2ProjectedGradientDescentAttack(steps=10)\n",
        "epsilons = 1.0\n",
        "\n",
        "# Transform adversarial images back to 32x32\n",
        "resize_to_32 = transforms.Resize((32, 32))"
      ],
      "metadata": {
        "id": "OegfRpNfyzn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import foolbox as fb\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "dImg9maXzISu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_dataset_path = \"./adversarial_dataset_32x32\"\n",
        "os.makedirs(adversarial_dataset_path, exist_ok=True)\n",
        "\n",
        "# Process dataset\n",
        "for i, (inputs, labels) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Adversarial Generation\"):\n",
        "    try:\n",
        "        # Move inputs to device\n",
        "        inputs = inputs.to(device).half()\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        with torch.cuda.amp.autocast():\n",
        "            raw_advs, clipped_advs, success = attack(fmodel, inputs, labels, epsilons=epsilons)\n",
        "\n",
        "        # Save images resized to 32x32 with the same filenames as originals, prefixed with \"adversarial_\"\n",
        "        for idx in range(inputs.size(0)):\n",
        "            # Get the original filename\n",
        "            original_path, _ = kaggle_dataset.samples[i * inputs.size(0) + idx]\n",
        "            original_filename = os.path.basename(original_path)\n",
        "            adversarial_filename = f\"adversarial_{original_filename}\"\n",
        "\n",
        "            # Create class directory in the output folder\n",
        "            class_name = kaggle_dataset.classes[labels[idx].item()]\n",
        "            class_dir = os.path.join(adversarial_dataset_path, class_name)\n",
        "            os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "            # Resize adversarial image to 32x32 and save\n",
        "            adversarial_32x32 = resize_to_32(clipped_advs[idx].float().cpu())\n",
        "            image_path = os.path.join(class_dir, adversarial_filename)\n",
        "            torchvision.utils.save_image(adversarial_32x32, image_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during batch {i + 1}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "JotSusbLy4h5",
        "outputId": "da9ed225-e11a-48e3-d3cd-3386b4b7724f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdversarial Generation:   0%|          | 0/12500 [00:00<?, ?it/s]<ipython-input-11-1dfb81ef3552>:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Adversarial Generation:   0%|          | 1/12500 [01:23<289:15:05, 83.31s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1dfb81ef3552>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Generate adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mraw_advs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipped_advs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Save images resized to 32x32 with the same filenames as originals, prefixed with \"adversarial_\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreal_epsilons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# clip to epsilon because we don't really know what the attack returns;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/foolbox/attacks/gradient_descent_base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgradient_step_sign\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/foolbox/attacks/gradient_descent_base.py\u001b[0m in \u001b[0;36mvalue_and_grad\u001b[0;34m(self, loss_fn, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     ) -> Tuple[ep.Tensor, ep.Tensor]:\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     def run(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/eagerpy/framework.py\u001b[0m in \u001b[0;36mvalue_and_grad\u001b[0;34m(f, t, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m ) -> Tuple[TensorType, TensorType]:\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/eagerpy/tensor/tensor.py\u001b[0m in \u001b[0;36mvalue_and_grad\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     ) -> Tuple[TensorType, TensorType]:\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_and_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/eagerpy/tensor/pytorch.py\u001b[0m in \u001b[0;36mvalue_and_grad\u001b[0;34m(x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linf attack\n"
      ],
      "metadata": {
        "id": "ChDThNYWhppN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/test\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Ensure input matches the original size (32x32)\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "0vnXb2fWhs3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_dataset = torchvision.datasets.ImageFolder(dataset_path, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(kaggle_dataset, batch_size=8, shuffle=False, num_workers=4, prefetch_factor=2)\n",
        "\n",
        "# Load pre-trained ResNet50\n",
        "model = torchvision.models.resnet50(pretrained=True).to(device).eval()\n",
        "model.half()  # Mixed precision\n",
        "fmodel = fb.PyTorchModel(model, bounds=(0, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFGE-Richtum",
        "outputId": "fdf9690c-7b44-42a1-a742-d15625288a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack = fb.attacks.LinfProjectedGradientDescentAttack(steps=10, rel_stepsize=0.1)\n",
        "epsilons = 16 / 255\n",
        "# Transform adversarial images back to 32x32\n",
        "resize_to_32 = transforms.Resize((32, 32))"
      ],
      "metadata": {
        "id": "EILKx_J5hxtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_dataset_path = \"./adversarial_dataset_inf_test\"\n",
        "os.makedirs(adversarial_dataset_path, exist_ok=True)\n",
        "\n",
        "# Process dataset\n",
        "for i, (inputs, labels) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Adversarial Generation\"):\n",
        "    try:\n",
        "        # Move inputs to device\n",
        "        inputs = inputs.to(device).half()\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        with torch.cuda.amp.autocast():\n",
        "            raw_advs, clipped_advs, success = attack(fmodel, inputs, labels, epsilons=epsilons)\n",
        "\n",
        "        # Save images resized to 32x32 with the same filenames as originals, prefixed with \"adversarial_\"\n",
        "        for idx in range(inputs.size(0)):\n",
        "            # Get the original filename\n",
        "            original_path, _ = kaggle_dataset.samples[i * inputs.size(0) + idx]\n",
        "            original_filename = os.path.basename(original_path)\n",
        "            adversarial_filename = f\"adversarial_{original_filename}\"\n",
        "\n",
        "            # Create class directory in the output folder\n",
        "            class_name = kaggle_dataset.classes[labels[idx].item()]\n",
        "            class_dir = os.path.join(adversarial_dataset_path, class_name)\n",
        "            os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "            # Resize adversarial image to 32x32 and save\n",
        "            adversarial_32x32 = resize_to_32(clipped_advs[idx].float().cpu())\n",
        "            image_path = os.path.join(class_dir, adversarial_filename)\n",
        "            torchvision.utils.save_image(adversarial_32x32, image_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during batch {i + 1}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "170kofVch6wi",
        "outputId": "8952aea6-be19-4b5a-de42-33790751a690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdversarial Generation:   0%|          | 0/2500 [00:00<?, ?it/s]<ipython-input-20-146a1715b439>:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Adversarial Generation: 100%|██████████| 2500/2500 [09:24<00:00,  4.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Path to the folder in Colab\n",
        "folder_to_download = \"/content/adversarial_dataset_inf_test\"  # Replace with your folder path\n",
        "output_zip = \"./adversarial_dataset_inf_test.zip\"\n",
        "\n",
        "# Compress the folder\n",
        "shutil.make_archive(output_zip.replace(\".zip\", \"\"), 'zip', folder_to_download)\n",
        "\n",
        "# Download the zipped folder\n",
        "files.download(output_zip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3D8cQ2p1iFnU",
        "outputId": "b5c4c0de-08e7-4adf-99f0-357848bdab78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_99b88168-ab38-493b-93b5-184d66599764\", \"adversarial_dataset_inf_test.zip\", 18133679)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M8-czfcgtV3X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}