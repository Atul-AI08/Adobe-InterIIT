{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the implementation of thr paper \"DIRE for Diffusion-Generated Image Detection\" , \"https://arxiv.org/pdf/2303.09295\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paODFQ3XU5YP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TD94QTk5U5YS"
   },
   "outputs": [],
   "source": [
    "def add_noise(image_tensor, timesteps=20):\n",
    "    noisy_image = image_tensor.clone()\n",
    "    for _ in range(timesteps):\n",
    "        noisy_image = noisy_image + torch.randn_like(noisy_image) * 0.05\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "def denoise(noisy_image_tensor, timesteps=10):\n",
    "    denoised_image = noisy_image_tensor.clone()\n",
    "    for _ in range(timesteps):\n",
    "        denoised_image = denoised_image - torch.randn_like(denoised_image) * 0.05\n",
    "    return denoised_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XU4N2BwdU5YS"
   },
   "outputs": [],
   "source": [
    "def ddim_inversion(image_tensor, timesteps=10, alpha_start=0.1, alpha_end=0.9):\n",
    "    \"\"\"Applies the DDIM inversion process by adding Gaussian noise over a series of timesteps.\"\"\"\n",
    "    noisy_image = image_tensor.clone()\n",
    "    alphas = (\n",
    "        torch.linspace(alpha_start, alpha_end, timesteps)\n",
    "        .to(image_tensor.device)\n",
    "        .type_as(image_tensor)\n",
    "    )\n",
    "\n",
    "    for t in range(timesteps):\n",
    "        alpha_t = alphas[t]\n",
    "        if t < timesteps - 1:\n",
    "            alpha_next = alphas[t + 1]\n",
    "        else:\n",
    "            alpha_next = alpha_end\n",
    "\n",
    "        epsilon_theta = torch.randn_like(\n",
    "            noisy_image\n",
    "        )  # Simulating model prediction noise\n",
    "\n",
    "        # Convert to tensors and clamp to avoid invalid values\n",
    "        alpha_t = torch.tensor(alpha_t, device=image_tensor.device).type_as(\n",
    "            image_tensor\n",
    "        )\n",
    "        alpha_next = torch.tensor(alpha_next, device=image_tensor.device).type_as(\n",
    "            image_tensor\n",
    "        )\n",
    "\n",
    "        # Ensure values inside sqrt are positive\n",
    "        alpha_ratio = torch.sqrt(torch.clamp(alpha_next / alpha_t, min=1e-6))\n",
    "        diff_sqrt = torch.sqrt(torch.clamp((1 - alpha_next) - (1 - alpha_t), min=1e-6))\n",
    "\n",
    "        noisy_image = noisy_image * alpha_ratio + epsilon_theta * diff_sqrt\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "def ddim_reconstruction(\n",
    "    noisy_image_tensor, timesteps=10, alpha_start=0.1, alpha_end=0.9\n",
    "):\n",
    "    \"\"\"Reconstructs the image from the noisy sample using the deterministic DDIM reverse process.\"\"\"\n",
    "    reconstructed_image = noisy_image_tensor.clone()\n",
    "    alphas = (\n",
    "        torch.linspace(alpha_start, alpha_end, timesteps)\n",
    "        .to(noisy_image_tensor.device)\n",
    "        .type_as(noisy_image_tensor)\n",
    "    )\n",
    "\n",
    "    for t in range(timesteps - 1, -1, -1):\n",
    "        alpha_t = alphas[t]\n",
    "        if t > 0:\n",
    "            alpha_prev = alphas[t - 1]\n",
    "        else:\n",
    "            alpha_prev = alpha_start\n",
    "\n",
    "        epsilon_theta = torch.randn_like(\n",
    "            reconstructed_image\n",
    "        )  # Simulating model prediction noise\n",
    "\n",
    "        # Convert to tensors and clamp to avoid invalid values\n",
    "        alpha_t = torch.tensor(alpha_t, device=noisy_image_tensor.device).type_as(\n",
    "            noisy_image_tensor\n",
    "        )\n",
    "        alpha_prev = torch.tensor(alpha_prev, device=noisy_image_tensor.device).type_as(\n",
    "            noisy_image_tensor\n",
    "        )\n",
    "\n",
    "        # Ensure values inside sqrt are positive\n",
    "        sqrt_alpha_t = torch.sqrt(torch.clamp(alpha_t, min=1e-6))\n",
    "        sqrt_one_minus_alpha_t = torch.sqrt(torch.clamp(1 - alpha_t, min=1e-6))\n",
    "\n",
    "        x_t = (\n",
    "            reconstructed_image * sqrt_alpha_t + epsilon_theta * sqrt_one_minus_alpha_t\n",
    "        )\n",
    "\n",
    "        # Update reconstructed_image based on deterministic reverse process\n",
    "        sqrt_alpha_ratio = torch.sqrt(torch.clamp(alpha_prev / alpha_t, min=1e-6))\n",
    "        diff_term = torch.sqrt(torch.clamp(1 - alpha_prev, min=1e-6)) - torch.sqrt(\n",
    "            torch.clamp((1 - alpha_t) / alpha_t, min=1e-6)\n",
    "        )\n",
    "\n",
    "        reconstructed_image = x_t * sqrt_alpha_ratio + diff_term * epsilon_theta\n",
    "\n",
    "    return reconstructed_image\n",
    "\n",
    "\n",
    "# DIRE calculation for a given image tensor\n",
    "def calculate_dire(image_tensor, timesteps=10):\n",
    "    # Perform inversion to noisy space and then reconstruct\n",
    "    noisy_image = ddim_inversion(image_tensor, timesteps=timesteps)\n",
    "    reconstructed_image = ddim_reconstruction(noisy_image, timesteps=timesteps)\n",
    "\n",
    "    # Check for NaNs in the reconstructed image\n",
    "    if torch.isnan(reconstructed_image).any():\n",
    "        print(\"Warning: NaN values found in reconstructed image\")\n",
    "        return float(\"nan\")\n",
    "\n",
    "    # Compute DIRE as the mean absolute difference\n",
    "    dire = torch.abs(image_tensor - reconstructed_image).mean().item()\n",
    "    return dire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsSc8-tHU5YT"
   },
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "real_dir = \"\\test\\REAL\"\n",
    "fake_dir = \"\\test\\FAKE\"\n",
    "\n",
    "# Dataframe to store DIRE values and labels\n",
    "data = {\"image_path\": [], \"DIRE\": [], \"label\": []}\n",
    "\n",
    "# Image transformation\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdclDAhHU5YU",
    "outputId": "1073dcd6-b174-4a5b-f585-80f3d28e457c"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"image_path\", \"DIRE\", \"label\"])\n",
    "\n",
    "# Load images, calculate DIRE, and store in the dataframe\n",
    "for label, folder in [(\"REAL\", real_dir), (\"FAKE\", fake_dir)]:\n",
    "    for filename in tqdm(\n",
    "        os.listdir(folder), desc=f\"Processing {label} images\", unit=\"file\"\n",
    "    ):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            image = Image.open(file_path).convert(\"RGB\")\n",
    "            image_tensor = transform(image)\n",
    "            dire_value = calculate_dire(image_tensor)\n",
    "            df = df.append(\n",
    "                {\n",
    "                    \"image_path\": file_path,\n",
    "                    \"DIRE\": dire_value,\n",
    "                    \"label\": 1 if label == \"REAL\" else 0,\n",
    "                },\n",
    "                ignore_index=True,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOv5qyHVU5YU",
    "outputId": "a690f430-8b96-4765-d262-0b8917babbde"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df[[\"DIRE\"]]\n",
    "y = df[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9Ev8WVBU5YU"
   },
   "outputs": [],
   "source": [
    "# Predictions and Evaluation\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KBKsRNsU5YU",
    "outputId": "2a5eea8e-c902-4abc-baf1-1c690b31c436"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
